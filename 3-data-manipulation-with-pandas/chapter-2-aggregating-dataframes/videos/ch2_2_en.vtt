WEBVTT

1
00:00:00.000 --> 00:00:06.440
So far, in this chapter, you've learned how to summarize numeric variables.

2
00:00:06.440 --> 00:00:10.720
In this video, you'll learn how to summarize categorical data using counting.

3
00:00:10.720 --> 00:00:10.720


4
00:00:10.720 --> 00:00:10.720


5
00:00:10.720 --> 00:00:16.480
Counting dogs is no easy task when they're running around the park.

6
00:00:16.480 --> 00:00:19.360
It's hard to keep track of who you have and haven't counted!

7
00:00:19.360 --> 00:00:19.360


8
00:00:19.360 --> 00:00:20.680


9
00:00:20.680 --> 00:00:24.000
Here's a DataFrame that contains vet visits.

10
00:00:24.000 --> 00:00:29.520
The vet's office wants to know how many dogs of each breed have visited their office.

11
00:00:29.520 --> 00:00:33.760
However, some dogs have been to the vet more than once, like Max and

12
00:00:33.760 --> 00:00:39.560
Stella, so we can't just count the number of each breed in the breed column.

13
00:00:39.560 --> 00:00:39.560


14
00:00:39.560 --> 00:00:39.560


15
00:00:39.560 --> 00:00:44.840
Let's try to fix this by removing rows that contain a dog name already listed earlier

16
00:00:44.840 --> 00:00:52.600
in the dataset, or in other words; we'll extract a dog with each name from the dataset once.

17
00:00:52.600 --> 00:00:52.600


18
00:00:52.600 --> 00:00:52.600


19
00:00:52.600 --> 00:00:56.600
We can do this using the drop_duplicates method.

20
00:00:56.600 --> 00:01:00.880
It takes an argument, subset, which is the column we want to find

21
00:01:00.880 --> 00:01:06.240
our duplicates based on - in this case, we want all the unique names.

22
00:01:06.240 --> 00:01:06.240


23
00:01:06.240 --> 00:01:06.240


24
00:01:06.240 --> 00:01:10.160
Now we have a list of dogs where each one appears once.

25
00:01:10.160 --> 00:01:13.680
We have Max the Chow Chow, but where did Max the Labrador go?

26
00:01:13.680 --> 00:01:13.680


27
00:01:13.680 --> 00:01:14.840


28
00:01:14.840 --> 00:01:17.840
Because we have two different dogs with the same name,

29
00:01:17.840 --> 00:01:22.440
we'll need to consider more than just name when dropping duplicates.

30
00:01:22.440 --> 00:01:22.440


31
00:01:22.440 --> 00:01:22.440


32
00:01:22.440 --> 00:01:25.640
Since Max and Max are different breeds, we can drop the

33
00:01:25.640 --> 00:01:29.640
rows with pairs of name and breed listed earlier in the dataset.

34
00:01:29.640 --> 00:01:29.640


35
00:01:29.640 --> 00:01:29.640


36
00:01:29.640 --> 00:01:35.360
To base our duplicate dropping on multiple columns, we can pass a

37
00:01:35.360 --> 00:01:39.640
list of column names to the subset argument, in this case, name and breed.

38
00:01:39.640 --> 00:01:40.800


39
00:01:40.800 --> 00:01:40.800


40
00:01:40.800 --> 00:01:43.960
Now both Maxes have been included, and we can start counting.

41
00:01:43.960 --> 00:01:43.960


42
00:01:43.960 --> 00:01:43.960


43
00:01:43.960 --> 00:01:51.000
To count the dogs of each breed, we'll subset the breed column and use the value_counts method.

44
00:01:51.000 --> 00:01:51.000


45
00:01:51.000 --> 00:01:51.040


46
00:01:51.040 --> 00:01:58.160
We can also use the sort argument to get the breeds with the biggest counts on top.

47
00:01:58.160 --> 00:01:58.160


48
00:01:58.160 --> 00:01:58.160


49
00:01:58.160 --> 00:02:02.400
The normalize argument can be used to turn the counts into proportions of the total.

50
00:02:02.400 --> 00:02:06.440
25% of the dogs that go to this vet are Labradors.

51
00:02:06.440 --> 00:02:06.440


52
00:02:06.440 --> 00:02:06.440


53
00:02:06.440 --> 00:02:10.800
Time to commence counting!

